{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d589d3",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/67f9255c-a1ec-8012-be33-0f10696efe98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2512ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ff5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revised training script\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from scripts.function_composition import HierarchicalCompositionalModel\n",
    "\n",
    "# Revised load_dataset function that loads intermediate steps and operations.\n",
    "def load_dataset(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    inputs = [sample['input'] for sample in data]\n",
    "    final_outputs = [sample['output'] for sample in data]\n",
    "    # Use intermediate_steps excluding the initial input (i.e. the output after each op)\n",
    "    intermediate_steps = [sample['intermediate_steps'][1:] for sample in data]\n",
    "    operations = [sample['operations'] for sample in data]\n",
    "    op_lengths = [len(sample['operations']) for sample in data]\n",
    "    max_len_in = max(len(x) for x in inputs)\n",
    "    padded_inputs = [x + [0]*(max_len_in - len(x)) for x in inputs]\n",
    "    max_len_out = max(len(x) for x in final_outputs)\n",
    "    padded_final_outputs = [x + [0]*(max_len_out - len(x)) for x in final_outputs]\n",
    "    # Pad intermediate steps: each sample is a list of lists (each inner list has length equal to input size)\n",
    "    max_steps = max(len(steps) for steps in intermediate_steps)\n",
    "    padded_intermediate = []\n",
    "    for steps in intermediate_steps:\n",
    "        step_len = len(steps[0])\n",
    "        if len(steps) < max_steps:\n",
    "            steps = steps + [[0]*step_len]*(max_steps - len(steps))\n",
    "        padded_intermediate.append(steps)\n",
    "    # Convert operations to indices\n",
    "    op_to_index = {'sort': 0, 'reverse': 1, 'add': 2, 'subtract': 3, 'multiply': 4, 'divide': 5}\n",
    "    max_ops = max(op_lengths)\n",
    "    padded_ops = []\n",
    "    for op_list in operations:\n",
    "        indices = [op_to_index[op] for op in op_list]\n",
    "        if len(indices) < max_ops:\n",
    "            indices = indices + [-1]*(max_ops - len(indices))\n",
    "        padded_ops.append(indices)\n",
    "    inputs_tensor = torch.tensor(padded_inputs, dtype=torch.float32)\n",
    "    final_outputs_tensor = torch.tensor(padded_final_outputs, dtype=torch.float32)\n",
    "    intermediate_tensor = torch.tensor(padded_intermediate, dtype=torch.float32)  # [N, max_steps, input_size]\n",
    "    operations_tensor = torch.tensor(padded_ops, dtype=torch.long)  # [N, max_ops]\n",
    "    op_lengths_tensor = torch.tensor(op_lengths, dtype=torch.long)\n",
    "    return inputs_tensor, final_outputs_tensor, intermediate_tensor, operations_tensor, op_lengths_tensor\n",
    "\n",
    "train_x, train_y, train_intermediates, train_ops, train_op_lengths = load_dataset('../datasets/function_composition/train_dataset.json')\n",
    "val_x, val_y, val_intermediates, val_ops, val_op_lengths = load_dataset('../datasets/function_composition/validation_dataset.json')\n",
    "test_x, test_y, test_intermediates, test_ops, test_op_lengths = load_dataset('../datasets/function_composition/test_dataset.json')\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y, train_intermediates, train_ops, train_op_lengths), batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_x, val_y, val_intermediates, val_ops, val_op_lengths), batch_size=8)\n",
    "test_loader = DataLoader(TensorDataset(test_x, test_y, test_intermediates, test_ops, test_op_lengths), batch_size=8)\n",
    "\n",
    "input_size = train_x.size(1)\n",
    "hidden_size = 64\n",
    "# Use the maximum number of intermediate steps as the sequence length.\n",
    "max_sequence_length = train_intermediates.size(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HierarchicalCompositionalModel(input_size, hidden_size, max_sequence_length).to(device)\n",
    "\n",
    "# Loss functions: MSE for intermediate outputs and CrossEntropy for operations.\n",
    "mse_loss_fn = nn.MSELoss(reduction='none')\n",
    "ce_loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "pbar = tqdm(range(num_epochs), desc=\"Epoch 0\")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, final_targets, intermediate_targets, operations_targets, op_lengths in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        final_targets = final_targets.to(device)\n",
    "        intermediate_targets = intermediate_targets.to(device)\n",
    "        operations_targets = operations_targets.to(device)\n",
    "        op_lengths = op_lengths.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, module_logits = model(inputs)  # outputs: [B, seq_len, input_size]\n",
    "                                               # module_logits: [B, seq_len, num_modules]\n",
    "        B, seq_len, _ = outputs.size()\n",
    "        # Create mask for valid intermediate steps (for each sample, valid steps: [0, op_length))\n",
    "        step_range = torch.arange(seq_len, device=device).unsqueeze(0)  # [1, seq_len]\n",
    "        mask = (step_range < op_lengths.unsqueeze(1)).float()  # [B, seq_len]\n",
    "        # Intermediate loss: compute MSE between predicted intermediate outputs and ground truth\n",
    "        diff = mse_loss_fn(outputs, intermediate_targets)  # [B, seq_len, input_size]\n",
    "        diff = diff.mean(dim=2)  # [B, seq_len]\n",
    "        intermediate_loss = (diff * mask).sum() / mask.sum()\n",
    "        # Operations loss: supervise the controller's module predictions\n",
    "        # Use only the valid steps (number of operations = max_ops for each sample)\n",
    "        logits_valid = module_logits[:, :operations_targets.size(1), :]  # [B, max_ops, num_modules]\n",
    "        operations_loss = ce_loss_fn(logits_valid.reshape(-1, logits_valid.size(-1)),\n",
    "                                       operations_targets.reshape(-1))\n",
    "        loss = intermediate_loss + operations_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, final_targets, intermediate_targets, operations_targets, op_lengths in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            final_targets = final_targets.to(device)\n",
    "            intermediate_targets = intermediate_targets.to(device)\n",
    "            operations_targets = operations_targets.to(device)\n",
    "            op_lengths = op_lengths.to(device)\n",
    "            outputs, module_logits = model(inputs)\n",
    "            B, seq_len, _ = outputs.size()\n",
    "            step_range = torch.arange(seq_len, device=device).unsqueeze(0)\n",
    "            mask = (step_range < op_lengths.unsqueeze(1)).float()\n",
    "            diff = mse_loss_fn(outputs, intermediate_targets)\n",
    "            diff = diff.mean(dim=2)\n",
    "            intermediate_loss = (diff * mask).sum() / mask.sum()\n",
    "            logits_valid = module_logits[:, :operations_targets.size(1), :]\n",
    "            operations_loss = ce_loss_fn(logits_valid.reshape(-1, logits_valid.size(-1)),\n",
    "                                           operations_targets.reshape(-1))\n",
    "            total_val_loss += (intermediate_loss + operations_loss).item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, final_targets, intermediate_targets, operations_targets, op_lengths in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        final_targets = final_targets.to(device)\n",
    "        intermediate_targets = intermediate_targets.to(device)\n",
    "        operations_targets = operations_targets.to(device)\n",
    "        op_lengths = op_lengths.to(device)\n",
    "        outputs, module_logits = model(inputs)\n",
    "        B, seq_len, _ = outputs.size()\n",
    "        step_range = torch.arange(seq_len, device=device).unsqueeze(0)\n",
    "        mask = (step_range < op_lengths.unsqueeze(1)).float()\n",
    "        diff = mse_loss_fn(outputs, intermediate_targets)\n",
    "        diff = diff.mean(dim=2)\n",
    "        intermediate_loss = (diff * mask).sum() / mask.sum()\n",
    "        logits_valid = module_logits[:, :operations_targets.size(1), :]\n",
    "        operations_loss = ce_loss_fn(logits_valid.reshape(-1, logits_valid.size(-1)),\n",
    "                                       operations_targets.reshape(-1))\n",
    "        total_test_loss += (intermediate_loss + operations_loss).item()\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "os.makedirs('./plots', exist_ok=True)\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('./plots/fc_model.png')\n",
    "plt.show()\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "torch.save(best_model, './models/best_fc_model.pth')\n",
    "print(\"Best model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
